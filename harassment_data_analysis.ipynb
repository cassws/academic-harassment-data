{"cells":[{"cell_type":"code","source":["# Investigating key research questions in the Sexual Harassment in Academia: Results of a Crowdsourced Survey dataset\n# Using NLP (topic modeling, classification, etc.) techniques with Spark, MLLIB, pandas, NLTK, and Python. \n# Final project for SI 618."],"metadata":{"collapsed":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":["from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer \nfrom pyspark.ml.feature import StopWordsRemover\nfrom pyspark.ml.clustering import LDA\nfrom pyspark.ml.pipeline import Pipeline\nimport numpy as np\nimport nltk"],"metadata":{"collapsed":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":["from nltk.tokenize import RegexpTokenizer\nfrom nltk.corpus import stopwords as nltkstopwords"],"metadata":{"collapsed":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":["df = spark.read.load(\"/FileStore/tables/harassment_mainrawdata_4_4_18.csv\",\n                     format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")"],"metadata":{"collapsed":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":["df.head()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["from pyspark.sql.types import ArrayType, StringType\n\ndef indices_to_terms(vocabulary):\n    def indices_to_terms(xs):\n        return [vocabulary[int(x)] for x in xs]\n    return udf(indices_to_terms, ArrayType(StringType()))"],"metadata":{"collapsed":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":["print(df.columns)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["df.count()\n# df = df.na.fill('')\nimport numpy as np\ndf = df.na.drop(subset=['event', 'perpetrator', 'mental', 'response', 'career', 'life', 'punishment', 'time'], how=\"any\")\n"],"metadata":{"collapsed":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":["from pyspark.sql.functions import regexp_replace\nfrom pyspark.sql import functions as F\n\nfor c in df.columns:\n  df = df.withColumn(c, regexp_replace(df[c], \"\\p{Punct}\", \"\"))\n  df = df.withColumn(c, F.lower(F.col(c)))\n# df.toDF(*[regexp_replace(df[c], \"\\p{Punct}\", \"\") for c in df.columns])\n# # for col in df.columns:\n# #     df = df.withColumn(col,regexp_replace(df[col], \"\\p{Punct}\", \"\")).collect()[0]\ndf.head(5)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["df.count()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["def blank_as_null(x):\n    return when(col(x) != \"\", col(x)).otherwise(None)\n\ndef blank_as_null_with_line(x):\n  return when(col(x) != \" \", col(x)).otherwise(None)\n\ndef blank_as_null_with_2line(x):\n  return when(col(x) != \"  \", col(x)).otherwise(None)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["from pyspark.sql.functions import col, when\n\ndef fullPipeline(kTerm, c):\n  currentDF = df\n\n  currentDF = currentDF.withColumn(c, blank_as_null(c))\n  currentDF = currentDF.withColumn(c, blank_as_null_with_line(c))\n  currentDF = currentDF.withColumn(c, blank_as_null_with_2line(c))\n\n  keep = currentDF.select([c])\n  currentDF = keep.na.drop(how=\"any\")\n  \n  \n  kT = kTerm\n\n  tokenizer = Tokenizer(inputCol=c, outputCol=\"words\")\n\n  stopWordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n  stopWordsRemover.loadDefaultStopWords(\"english\")\n\n#   vectorizer = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", minDF=2) \n  vectorizer = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", minDF=2) \n\n  print (\"k = \",kT)\n  lda = LDA(k=kT, maxIter=10)\n\n  pipeline = Pipeline(stages=[tokenizer, stopWordsRemover, vectorizer, lda])\n  pipelineModel = pipeline.fit(currentDF)\n\n  countVectorModel = pipelineModel.stages[-2]\n  cmv = countVectorModel.vocabulary\n  print(\"Vocab length is\",len(cmv))\n\n  ldaModel = pipelineModel.stages[-1]\n\n  # Assess the model\n  df_lda = pipelineModel.transform(currentDF)\n\n  lp = ldaModel.logPerplexity(df_lda)\n  print(\"Log perplexity  (lower is better): \",lp)\n  ll = ldaModel.logLikelihood(df_lda)\n  print(\"Log likelihood (higher is better): \",ll)\n  # Describe topics.\n\n  topics = ldaModel.describeTopics(8)\n\n  topics = topics.withColumn(\n      \"topicWords\", indices_to_terms(countVectorModel.vocabulary)(\"termIndices\"))\n  topics.select(\"topicWords\").show(10,truncate=False)\n  \n  return topics\n"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["fullPipeline(7, \"response\")"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["fullPipeline(10, \"response\")"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["fullPipeline(10, \"event\")"],"metadata":{"collapsed":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":["fullPipeline(5, \"event\")"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["fullPipeline(10, \"mental\")"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["fullPipeline(10, \"life\")"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["fullPipeline(6, \"mental\")"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["fullPipeline(5, \"event\")"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["num_topics = 20\ne_outTopics = fullPipeline(num_topics, \"event\")\ne_outTopics.select(\"topicWords\").show(num_topics,truncate=False)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["r_outTopics = fullPipeline(num_topics, \"response\")\nr_outTopics.select(\"topicWords\").show(num_topics,truncate=False)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["p_outTopics = fullPipeline(num_topics, \"punishment\")\np_outTopics.select(\"topicWords\").show(num_topics,truncate=False)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["c_outTopics = fullPipeline(num_topics, \"career\")\nc_outTopics.select(\"topicWords\").show(num_topics,truncate=False)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["m_outTopics = fullPipeline(num_topics, \"mental\")\nm_outTopics.select(\"topicWords\").show(num_topics,truncate=False)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["l_outTopics = fullPipeline(num_topics, \"life\")\nl_outTopics.select(\"topicWords\").show(num_topics,truncate=False)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["num_topics = 10\ne_outTopics = fullPipeline(num_topics, \"event\")\ne_outTopics.select(\"topicWords\").show(num_topics,truncate=False)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["num_topics = 15\ne_outTopics = fullPipeline(num_topics, \"event\")\ne_outTopics.select(\"topicWords\").show(num_topics,truncate=False)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["display(e_outTopics.select(\"topicWords\"))"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["r_outTopics = fullPipeline(num_topics, \"response\")\ndisplay(r_outTopics.select(\"topicWords\"))"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["p_outTopics = fullPipeline(num_topics, \"punishment\")\ndisplay(p_outTopics.select(\"topicWords\"))"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["m_outTopics = fullPipeline(num_topics, \"mental\")\ndisplay(m_outTopics.select(\"topicWords\"))"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["l_outTopics = fullPipeline(num_topics, \"life\")\ndisplay(l_outTopics.select(\"topicWords\"))"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["c_outTopics = fullPipeline(num_topics, \"career\")\ndisplay(c_outTopics.select(\"topicWords\"))"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["import pandas\n\npandasDF = df.toPandas()\npandasDF['IsProf'] = pandasDF['perpetrator'].str.contains(\"prof|chair|faculty\")\npandasDF['IsProf'] = (pandasDF['IsProf'] == True).astype(int)\n\n\n# spark_df = sqlContext.createDataFrame(pOut)\n\n"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["pandasDF.columns"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["pandasDF.rename(columns={'time':'time2'}, inplace=True)"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["import numpy as np\n# pandasDF.replace(r'\\s+', np.nan, regex=True)\n# pandasDF.dropna(subset=['event', 'perpetrator', 'mental', 'response', 'career'], how=\"any\")"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["len(pandasDF)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["\nprofOut = pandasDF[['time2', 'IsProf']].loc[pandasDF['IsProf'] == True]\nnot_profOut = pandasDF[['time2', 'IsProf']].loc[pandasDF['IsProf'] == False]"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["pandasDF.head()"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["all_with_indicators = sqlContext.createDataFrame(pandasDF[['time2', 'IsProf']])"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["profs_df = sqlContext.createDataFrame(profOut)\nnot_profs_df = sqlContext.createDataFrame(not_profOut)"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["professors_spark = df.join(profs_df, df.time == profs_df.time2, 'right')\nno_professors_spark = df.join(not_profs_df, df.time == not_profs_df.time2, 'right')"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["all_with_indicators_spark = df.join(all_with_indicators, df.time == all_with_indicators.time2, 'right')\n"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["all_with_indicators_spark.count()"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["all_with_indicators_spark.show(5)"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["professors_spark.count()"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["no_professors_spark.count()"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["def fullPipelineDFSpecific(theData, kTerm, c):\n  kT = kTerm\n  \n  theData = theData.withColumn(c, blank_as_null(c))\n  theData = theData.withColumn(c, blank_as_null_with_line(c))\n  theData = theData.withColumn(c, blank_as_null_with_2line(c))\n\n  keep = theData.select([c])\n  theData = keep.na.drop(how=\"any\")\n\n  tokenizer = Tokenizer(inputCol=c, outputCol=\"words\")\n\n  stopWordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n  stopWordsRemover.loadDefaultStopWords(\"english\")\n\n#   vectorizer = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", minDF=2) \n  vectorizer = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", minDF=2) \n\n  print (\"k = \",kT)\n  lda = LDA(k=kT, maxIter=10)\n\n  pipeline = Pipeline(stages=[tokenizer, stopWordsRemover, vectorizer, lda])\n  pipelineModel = pipeline.fit(theData)\n\n  countVectorModel = pipelineModel.stages[-2]\n  cmv = countVectorModel.vocabulary\n  print(\"Vocab length is\",len(cmv))\n\n  ldaModel = pipelineModel.stages[-1]\n\n  # Assess the model\n  df_lda = pipelineModel.transform(theData)\n\n  lp = ldaModel.logPerplexity(df_lda)\n  print(\"Log perplexity  (lower is better): \",lp)\n  ll = ldaModel.logLikelihood(df_lda)\n  print(\"Log likelihood (higher is better): \",ll)\n  # Describe topics.\n\n  topics = ldaModel.describeTopics(8)\n\n  topics = topics.withColumn(\n      \"topicWords\", indices_to_terms(countVectorModel.vocabulary)(\"termIndices\"))\n  topics.select(\"topicWords\").show(10,truncate=False)\n  \n  return topics\n"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["mental_prof_topics = fullPipelineDFSpecific(professors_spark, num_topics, \"mental\")\ndisplay(mental_prof_topics.select(\"topicWords\"))"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":["mental_noprof_topics = fullPipelineDFSpecific(no_professors_spark, num_topics, \"mental\")\ndisplay(mental_noprof_topics.select(\"topicWords\"))"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"code","source":["mr_prof_topics = fullPipelineDFSpecific(professors_spark, num_topics, \"response\")\ndisplay(mr_prof_topics.select(\"topicWords\"))"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"code","source":["mr_noprof_topics = fullPipelineDFSpecific(no_professors_spark, num_topics, \"response\")\ndisplay(mr_noprof_topics.select(\"topicWords\"))"],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"code","source":["p_prof_topics = fullPipelineDFSpecific(professors_spark, num_topics, \"punishment\")\ndisplay(p_prof_topics.select(\"topicWords\"))"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"code","source":["p_noprof_topics = fullPipelineDFSpecific(no_professors_spark, num_topics, \"response\")\ndisplay(p_noprof_topics.select(\"topicWords\"))"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"code","source":["c_prof_topics = fullPipelineDFSpecific(professors_spark, num_topics, \"career\")\ndisplay(c_prof_topics.select(\"topicWords\"))"],"metadata":{},"outputs":[],"execution_count":57},{"cell_type":"code","source":["c_noprof_topics = fullPipelineDFSpecific(no_professors_spark, num_topics, \"career\")\ndisplay(c_noprof_topics.select(\"topicWords\"))"],"metadata":{},"outputs":[],"execution_count":58},{"cell_type":"code","source":["full_profOut = pandasDF.loc[pandasDF['IsProf'] == True]\nfull_not_profOut = pandasDF.loc[pandasDF['IsProf'] == False]\n"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"code","source":["from pyspark.ml.feature import NGram\nfrom pyspark.ml import Pipeline\n\ndef generateNGrams(theData, col, n):\n  tokenizer = Tokenizer(inputCol=col, outputCol=\"words\")\n  stopWordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n  stopWordsRemover.loadDefaultStopWords(\"english\")\n\n  ngrams = NGram(n=n, inputCol='words', outputCol=col + \"_\" + str(n)+'-grams')\n\n  # build pipeline model\n  pipeline = Pipeline(stages=[tokenizer, stopWordsRemover,ngrams])\n\n  # transform data\n  text_ngrams = pipeline.fit(theData).transform(theData)\n  return text_ngrams"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"code","source":["out = generateNGrams(professors_spark, \"mental\", 3)"],"metadata":{},"outputs":[],"execution_count":61},{"cell_type":"code","source":["outPandas = out.toPandas()[['mental_3-grams']]"],"metadata":{},"outputs":[],"execution_count":62},{"cell_type":"code","source":["outPandas.head(5)\nrowsDict = {}\n\nfor index, row in outPandas.iterrows():\n   if len(row['mental_3-grams']) > 0:\n      for ngram in row['mental_3-grams']:\n        if ngram not in rowsDict:\n          rowsDict[ngram] = 0\n        rowsDict[ngram] += 1\n        \nngramSorted = sorted(rowsDict, key=rowsDict.get, reverse=True)\nfor top in ngramSorted[0:20]:\n  print(str(top) + \": \"+ str(rowsDict[top]))\n"],"metadata":{},"outputs":[],"execution_count":63},{"cell_type":"code","source":["def generateNGramsFull(theData, col, n):\n  ngram_string = col + \"_\" + str(n)+'-grams'\n  tokenizer = Tokenizer(inputCol=col, outputCol=\"words\")\n  stopWordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n  stopWordsRemover.loadDefaultStopWords(\"english\")\n\n  ngrams = NGram(n=n, inputCol='words', outputCol=ngram_string)\n\n  # build pipeline model\n  pipeline = Pipeline(stages=[tokenizer, stopWordsRemover,ngrams])\n\n  # transform data\n  text_ngrams = pipeline.fit(theData).transform(theData)\n  \n  outPandas = text_ngrams.toPandas()[[ngram_string]]\n  \n  rowsDict = {}\n\n  for index, row in outPandas.iterrows():\n     if len(row[ngram_string]) > 0:\n        for ngram in row[ngram_string]:\n          if ngram not in rowsDict:\n            rowsDict[ngram] = 0\n          rowsDict[ngram] += 1\n\n  ngramSorted = sorted(rowsDict, key=rowsDict.get, reverse=True)\n  sorted_top = []\n  for top in ngramSorted[0:20]:\n    sorted_top.append({\"ngram\": top, \"count\": rowsDict[top]})\n\n  \n  return pandas.DataFrame(sorted_top)"],"metadata":{},"outputs":[],"execution_count":64},{"cell_type":"code","source":["import seaborn as sns\nimport matplotlib.pyplot as plt"],"metadata":{},"outputs":[],"execution_count":65},{"cell_type":"code","source":["outResponse = generateNGramsFull(professors_spark, \"response\", 3)[0:12]\n\nviz_left_response = response_left_output[0:12]\nf, ax = plt.subplots(figsize=(12, 12))\nsns.set(style=\"darkgrid\")\nsns.barplot(y=\"ngram\",x=\"count\",data=outResponse).set_title('Common trigrams in \"response\" descriptions for professor/factuly/chair perpetrators')\n\nf.subplots_adjust(left=0.2)\ndisplay(f.figure)"],"metadata":{},"outputs":[],"execution_count":66},{"cell_type":"code","source":["generateNGramsFull(no_professors_spark, \"response\", 3)"],"metadata":{},"outputs":[],"execution_count":67},{"cell_type":"code","source":["generateNGramsFull(professors_spark, \"career\", 3)"],"metadata":{},"outputs":[],"execution_count":68},{"cell_type":"code","source":["prof_career_4 = generateNGramsFull(professors_spark, \"career\", 4)\n\nf, ax = plt.subplots(figsize=(12, 12))\nsns.set(style=\"darkgrid\")\nsns.barplot(y=\"index\",x=\"featureImportances\",data=viz_left_response).set_title('Response descriptors in sexual harassment reports that predict \"left\" or \"quit\" outcomes')\n\nf.subplots_adjust(left=0.2)\ndisplay(f.figure)"],"metadata":{},"outputs":[],"execution_count":69},{"cell_type":"code","source":["generateNGramsFull(professors_spark, \"punishment\", 3)"],"metadata":{},"outputs":[],"execution_count":70},{"cell_type":"code","source":["generateNGramsFull(professors_spark, \"event\", 3)"],"metadata":{},"outputs":[],"execution_count":71},{"cell_type":"code","source":["generateNGramsFull(professors_spark, \"event\", 4)"],"metadata":{},"outputs":[],"execution_count":72},{"cell_type":"code","source":["generateNGramsFull(no_professors_spark, \"event\", 4)"],"metadata":{},"outputs":[],"execution_count":73},{"cell_type":"code","source":["generateNGramsFull(professors_spark, \"response\", 4)"],"metadata":{},"outputs":[],"execution_count":74},{"cell_type":"code","source":["generateNGramsFull(professors_spark, \"punishment\", 4)"],"metadata":{},"outputs":[],"execution_count":75},{"cell_type":"code","source":["generateNGramsFull(no_professors_spark, \"response\", 4)"],"metadata":{},"outputs":[],"execution_count":76},{"cell_type":"code","source":["generateNGramsFull(no_professors_spark, \"punishment\", 5)"],"metadata":{},"outputs":[],"execution_count":77},{"cell_type":"code","source":["out_prof_event_4 = generateNGramsFull(professors_spark, \"event\", 4)[0:8]\n\nf, ax = plt.subplots(figsize=(9, 9))\nsns.set(style=\"darkgrid\")\nsns.barplot(y=\"ngram\",x=\"count\",data=out_prof_event_4).set_title('Common 4-grams in \"event\" descriptions for professor/faculty/chair perpetrators')\n\nf.subplots_adjust(left=0.25)\ndisplay(f.figure)"],"metadata":{},"outputs":[],"execution_count":78},{"cell_type":"code","source":["out_noprof_event_4 = generateNGramsFull(no_professors_spark, \"event\", 4)[0:8]\n\nf, ax = plt.subplots(figsize=(9, 9))\nsns.set(style=\"darkgrid\")\nsns.barplot(y=\"ngram\",x=\"count\",data=out_noprof_event_4).set_title('Common 4-grams in \"event\" descriptions for non-faculty perpetrators')\n\nf.subplots_adjust(left=0.25)\ndisplay(f.figure)"],"metadata":{},"outputs":[],"execution_count":79},{"cell_type":"code","source":["out_prof_punishment_3 = generateNGramsFull(professors_spark, \"punishment\", 3)[0:8]\n\nf, ax = plt.subplots(figsize=(9, 9))\nsns.set(style=\"darkgrid\")\nsns.barplot(y=\"ngram\",x=\"count\",data=out_prof_punishment_3).set_title('Common trigrams in \"punishment\" descriptions for Professor/Faculty/Chair perpetrators')\n\nf.subplots_adjust(left=0.25)\ndisplay(f.figure)"],"metadata":{},"outputs":[],"execution_count":80},{"cell_type":"code","source":["out_noprof_punishment_3 = generateNGramsFull(no_professors_spark, \"punishment\", 3)[0:8]\n\nf, ax = plt.subplots(figsize=(9, 9))\nsns.set(style=\"darkgrid\")\nsns.barplot(y=\"ngram\",x=\"count\",data=out_noprof_punishment_3).set_title('Common trigrams in \"punishment\" descriptions for non-faculty perpetrators')\n\nf.subplots_adjust(left=0.25)\ndisplay(f.figure)"],"metadata":{},"outputs":[],"execution_count":81},{"cell_type":"code","source":["generateNGramsFull(professors_spark, \"career\", 5)"],"metadata":{},"outputs":[],"execution_count":82},{"cell_type":"code","source":["generateNGramsFull(professors_spark, \"mental\", 5)"],"metadata":{},"outputs":[],"execution_count":83},{"cell_type":"code","source":["for c in [\"event\",\"punishment\",\"response\",\"mental\",\"career\",\"life\"]:\n  for n in [3,4,5]:\n    print(c+ ',' + str(n)+'-grams,\\n')\n    generateNGramsFull(professors_spark, c, n)"],"metadata":{},"outputs":[],"execution_count":84},{"cell_type":"code","source":["all_with_indicators_spark.show(5)"],"metadata":{},"outputs":[],"execution_count":85},{"cell_type":"markdown","source":["#Training a Classifier"],"metadata":{}},{"cell_type":"code","source":["# #drop nulls!!!!\n\n# from pyspark.sql.functions import col, isnan, when, trim\n\n# print(all_with_indicators_spark.count())\n\n# def to_null(c):\n#     return when(~(col(c).isNull() | isnan(col(c)) | (trim(col(c)) == \" \")), col(c))\n\n# columnsToConsider = ['perpetrator', 'response', 'mental', 'life', 'event']\n\n# all_with_indicators_spark.select([to_null(c).alias(c) for c in columnsToConsider]).na.drop()\n# print(all_with_indicators_spark.count())\n"],"metadata":{},"outputs":[],"execution_count":87},{"cell_type":"code","source":["columnsToNullifyBlanks = ['perpetrator', 'career', 'response', 'mental', 'life', 'event']\n\nfrom pyspark.sql.functions import col, when\n\ndef blank_as_null(x):\n    return when(col(x) != \"\", col(x)).otherwise(None)\n\ndef blank_as_null_with_line(x):\n  return when(col(x) != \" \", col(x)).otherwise(None)\n\ndef blank_as_null_with_2line(x):\n  return when(col(x) != \"  \", col(x)).otherwise(None)\n\nfor c in columnsToNullifyBlanks:\n  all_with_indicators_spark = all_with_indicators_spark.withColumn(c, blank_as_null(c))\n  all_with_indicators_spark = all_with_indicators_spark.withColumn(c, blank_as_null_with_line(c))\n  all_with_indicators_spark = all_with_indicators_spark.withColumn(c, blank_as_null_with_2line(c))\n\ncolumnsToNullifyBlanks.append('IsProf')\nkeep = all_with_indicators_spark.select(columnsToNullifyBlanks)\nall_with_indicators_spark = keep.na.drop(how=\"any\")"],"metadata":{},"outputs":[],"execution_count":88},{"cell_type":"code","source":["all_with_indicators_spark.show(15)"],"metadata":{},"outputs":[],"execution_count":89},{"cell_type":"code","source":["all_with_indicators_spark.count()"],"metadata":{},"outputs":[],"execution_count":90},{"cell_type":"code","source":["from pyspark.ml.feature import CountVectorizer\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\ndef ClassifierWithVector(theData, col):\n  splits = theData.randomSplit([0.8, 0.2], 1234)\n\n  # Training gets the 80%\n  theData_train = splits[0]\n\n  # Testing gets the 20%\n  theData_test = splits[1]\n\n  tokenizer = Tokenizer(inputCol=col, outputCol=\"words\")\n\n  stopWordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n  stopWordsRemover.loadDefaultStopWords(\"english\")\n\n#   vectorizer = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", minDF=2) \n  cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=300, minDF=4.0)\n  rf = RandomForestClassifier(labelCol=\"IsProf\", featuresCol=\"features\", numTrees=64)\n\n  pipeline = Pipeline(stages=[tokenizer, stopWordsRemover, cv, rf])\n  pipelineModel = pipeline.fit(theData_train)\n  pipelinePredictions = pipelineModel.transform(theData_test)\n#   display(pipelinePredictions.select(\"prediction\",\"IsProf\"))\n  \n  # compute accuracy on the test set\n  evaluator = MulticlassClassificationEvaluator(labelCol=\"IsProf\", predictionCol=\"prediction\",metricName=\"accuracy\")\n  accuracy = evaluator.evaluate(pipelinePredictions)\n  print(\"Test set accuracy = \" + str(accuracy))\n#   print(pipelineModel.vocabulary)\n\n#   featureImportances2 = pandas.DataFrame({\"index\":pipelineModel.vocabulary,\"featureImportances\":})\\\n#     .sort_values(\"featureImportances\", ascending=False)\n#   print(featureImportances)\n#   print(pipelineModel.stages[-2].vocabulary)\n#   print(pipelineModel.stages[-1].featureImportances)\n  featureImportances = pandas.DataFrame({\"index\":pipelineModel.stages[-2].vocabulary,\"featureImportances\":pipelineModel.stages[-1].featureImportances}).sort_values(\"featureImportances\", ascending=False)\n  print(featureImportances)\n  return featureImportances\n\n"],"metadata":{},"outputs":[],"execution_count":91},{"cell_type":"code","source":["event_prof_output= ClassifierWithVector(all_with_indicators_spark, \"event\")"],"metadata":{},"outputs":[],"execution_count":92},{"cell_type":"code","source":["response_prof_output = ClassifierWithVector(all_with_indicators_spark, \"response\")\n"],"metadata":{},"outputs":[],"execution_count":93},{"cell_type":"code","source":["type(response_prof_output.ix[0]['index'])"],"metadata":{},"outputs":[],"execution_count":94},{"cell_type":"code","source":["mental_prof_output = ClassifierWithVector(all_with_indicators_spark, \"mental\")"],"metadata":{},"outputs":[],"execution_count":95},{"cell_type":"code","source":["career_prof_output = ClassifierWithVector(all_with_indicators_spark, \"career\")\n"],"metadata":{},"outputs":[],"execution_count":96},{"cell_type":"code","source":["life_prof_output = ClassifierWithVector(all_with_indicators_spark, \"life\")"],"metadata":{},"outputs":[],"execution_count":97},{"cell_type":"code","source":["pandasDF2 = df.toPandas()\n# Merge cells\npandasDF2['combined']=pandasDF2['career'].astype(str)+' '+ pandasDF2['life'].astype(str) + pandasDF2['mental'].astype(str)\npandasDF2['Left'] = pandasDF2['combined'].str.contains(\"left|quit|change\")\npandasDF2['Left'] = (pandasDF2['Left'] == True).astype(int)\npandasDF2['Left'].value_counts()"],"metadata":{},"outputs":[],"execution_count":98},{"cell_type":"code","source":["pandasDF2.rename(columns={'time':'time2'}, inplace=True)"],"metadata":{},"outputs":[],"execution_count":99},{"cell_type":"code","source":["left_with_indicators = sqlContext.createDataFrame(pandasDF2[['time2', 'Left']])\nleft_with_indicators_spark = df.join(left_with_indicators, df.time == left_with_indicators.time2, 'right')"],"metadata":{},"outputs":[],"execution_count":100},{"cell_type":"code","source":["columnsToNullifyBlanks = ['perpetrator', 'career', 'response', 'mental', 'life', 'event', 'punishment']\n\ndef blank_as_null(x):\n    return when(col(x) != \"\", col(x)).otherwise(None)\n\ndef blank_as_null_with_line(x):\n  return when(col(x) != \" \", col(x)).otherwise(None)\n\ndef blank_as_null_with_2line(x):\n  return when(col(x) != \"  \", col(x)).otherwise(None)\n\nfor c in columnsToNullifyBlanks:\n  left_with_indicators_spark = left_with_indicators_spark.withColumn(c, blank_as_null(c))\n  left_with_indicators_spark = left_with_indicators_spark.withColumn(c, blank_as_null_with_line(c))\n  left_with_indicators_spark = left_with_indicators_spark.withColumn(c, blank_as_null_with_2line(c))\n\ncolumnsToNullifyBlanks.append('Left')\nkeep = left_with_indicators_spark.select(columnsToNullifyBlanks)\nleft_with_indicators_spark = keep.na.drop(how=\"any\")"],"metadata":{},"outputs":[],"execution_count":101},{"cell_type":"code","source":["def LeftClassifierWithVector(theData, col):\n  splits = theData.randomSplit([0.85, 0.15], 123)\n\n  # Training gets the 80%\n  theData_train = splits[0]\n\n  # Testing gets the 20%\n  theData_test = splits[1]\n\n  tokenizer = Tokenizer(inputCol=col, outputCol=\"words\")\n\n  stopWordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n  stopWordsRemover.loadDefaultStopWords(\"english\")\n\n#   vectorizer = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", minDF=2) \n  cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=150, minDF=4.0)\n  rf = RandomForestClassifier(labelCol=\"Left\", featuresCol=\"features\", numTrees=64)\n\n  pipeline = Pipeline(stages=[tokenizer, stopWordsRemover, cv, rf])\n  pipelineModel = pipeline.fit(theData_train)\n  pipelinePredictions = pipelineModel.transform(theData_test)\n#   display(pipelinePredictions.select(\"prediction\",\"IsProf\"))\n  \n  # compute accuracy on the test set\n  evaluator = MulticlassClassificationEvaluator(labelCol=\"Left\", predictionCol=\"prediction\",metricName=\"accuracy\")\n  accuracy = evaluator.evaluate(pipelinePredictions)\n  print(\"Test set accuracy = \" + str(accuracy))\n#   print(pipelineModel.vocabulary)\n\n#   featureImportances2 = pandas.DataFrame({\"index\":pipelineModel.vocabulary,\"featureImportances\":})\\\n#     .sort_values(\"featureImportances\", ascending=False)\n#   print(featureImportances)\n#   print(pipelineModel.stages[-2].vocabulary)\n#   print(pipelineModel.stages[-1].featureImportances)\n  featureImportances = pandas.DataFrame({\"index\":pipelineModel.stages[-2].vocabulary,\"featureImportances\":pipelineModel.stages[-1].featureImportances}).sort_values(\"featureImportances\", ascending=False)\n  print(featureImportances)\n  return featureImportances\n"],"metadata":{},"outputs":[],"execution_count":102},{"cell_type":"code","source":["response_left_output = LeftClassifierWithVector(left_with_indicators_spark, \"response\")"],"metadata":{},"outputs":[],"execution_count":103},{"cell_type":"code","source":["event_left_output = LeftClassifierWithVector(left_with_indicators_spark, \"event\")"],"metadata":{},"outputs":[],"execution_count":104},{"cell_type":"code","source":["punishment_left_output = LeftClassifierWithVector(left_with_indicators_spark, \"punishment\")"],"metadata":{},"outputs":[],"execution_count":105},{"cell_type":"markdown","source":["## Visualizations of important factors to predict outcomes (prof or no prof, left/quit or no)"],"metadata":{}},{"cell_type":"code","source":["import seaborn as sns\nimport matplotlib.pyplot as plt\n\nviz_left_event = event_left_output[0:12]\nf, ax = plt.subplots(figsize=(9, 9))\nsns.set(style=\"darkgrid\")\nsns.barplot(y=\"index\",x=\"featureImportances\",data=viz_left_event).set_title('Event descriptors in sexual harassment reports that are predictive of \"left\"/\"quit\" outcomes')\n\nf.subplots_adjust(left=0.15)\ndisplay(f.figure)"],"metadata":{},"outputs":[],"execution_count":107},{"cell_type":"code","source":["import seaborn as sns\nimport matplotlib.pyplot as plt\n\nviz_left_response = response_left_output[0:12]\nf, ax = plt.subplots(figsize=(9, 9))\nsns.set(style=\"darkgrid\")\nsns.barplot(y=\"index\",x=\"featureImportances\",data=viz_left_response).set_title('Response descriptors in sexual harassment reports that are predictive of \"left\"/\"quit\" outcomes')\n\nf.subplots_adjust(left=0.15)\ndisplay(f.figure)"],"metadata":{},"outputs":[],"execution_count":108},{"cell_type":"code","source":["import seaborn as sns\nimport matplotlib.pyplot as plt\n\nviz_left_punishment = punishment_left_output[0:12]\nf, ax = plt.subplots(figsize=(9, 9))\nsns.set(style=\"darkgrid\")\nsns.barplot(y=\"index\",x=\"featureImportances\",data=viz_left_punishment).set_title('Punishment descriptors in sexual harassment reports that are predictive of \"left\"/\"quit\" outcomes')\n\nf.subplots_adjust(left=0.15)\ndisplay(f.figure)"],"metadata":{},"outputs":[],"execution_count":109}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3","nbconvert_exporter":"python","file_extension":".py"},"name":"harassment_data_analysis","notebookId":4195318800557656},"nbformat":4,"nbformat_minor":0}
